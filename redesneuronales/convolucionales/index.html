
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Aprendizaje progresivo para conocer las posibilidades de la IA.">
      
      
        <meta name="author" content="IES Severo Ochoa">
      
      
        <link rel="canonical" href="https://sever8a.github.io/neuronal/redesneuronales/convolucionales/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.0b4">
    
    
      
        <title>Redes Convolucionales - Deep Learning</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.91872f81.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.2505c338.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-Y671WB1DQM"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-Y671WB1DQM",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-Y671WB1DQM",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>

  
    <script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="None" data-md-color-accent="None">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#redes-convolucionales" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="Deep Learning" class="md-header__button md-logo" aria-label="Deep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Deep Learning
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Redes Convolucionales
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="Deep Learning" class="md-nav__button md-logo" aria-label="Deep Learning" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Deep Learning
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Comenzando
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../proceso/" class="md-nav__link">
        El proceso
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../deep_learning/" class="md-nav__link">
        Machine vs Deep
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Pasos básicos
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Pasos básicos" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Pasos básicos
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../exploradatos/" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../exploradatos/" class="md-nav__link">
        Análisis Exploratorio
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../machinelearning/" class="md-nav__link">
        Machine Learning
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Redes Neuronales
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Redes Neuronales" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Redes Neuronales
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../" class="md-nav__link">
        Redes Neuronales
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../fundamentos/" class="md-nav__link">
        Fundamentos
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../redes_profundas/" class="md-nav__link">
        Redes Densas
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../temporales/" class="md-nav__link">
        Redes Recurrentes/LSTM
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Redes Convolucionales
      </a>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../hiperparametros/" class="md-nav__link">
        Hiperparámetros
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../gan/" class="md-nav__link">
        Redes Generativas Adversarias
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../transferencia/" class="md-nav__link">
        Transferencia de conocimiento
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../nlp/" class="md-nav__link">
        Procesamiento Lenguaje Natural
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../no_supervisado/" class="md-nav__link">
        Aprendizaje no supervisado
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../tareas1/" class="md-nav__link">
        Tareas
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="redes-convolucionales">Redes convolucionales</h1>
<p>Las redes convolucionales ofrecen ventajas, frente a las redes de capas densas, para el procesamiento de imágenes.</p>
<p><img alt="&quot;Esquema convolucional&quot;" src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*CrjJwSX9S7f759dK2EtGJQ.png" /></p>
<p>Las capas convolucionales son el elemento clave en este tipo de redes.</p>
<p>Se basan en el reconocimiento de elementos característicos de cada imagen. Aprende de líneas, bordes, texturas o formas.</p>
<p><img alt="&quot;Aprendizaje&quot;" src="https://www.researchgate.net/profile/Honglak-Lee/publication/220424626/figure/fig2/AS:277417953382421@1443153002703/Columns-1-4-the-second-layer-bases-top-and-the-third-layer-bases-bottom-learned-from.png" /></p>
<p>La primera capa convolucional aprende patrones básicos, y las siguientes capas aprenden patrones compuestos de las capas anteriores, cada vez más complejos.</p>
<p><img alt="aprendizaje de una cara" src="http://torres.ai/wp-content/uploads/2018/06/Picture.4.1.png" /></p>
<p>Las dos capas que definen a las redes convolucionales están especializadas en dos operaciones: <em>convolution</em> y <em>pooling</em>.</p>
<h1 id="de-capas-densas-a-capas-convolucionales">De capas densas a capas convolucionales</h1>
<p>Las capas convolucionales <strong>aprenden patrones locales</strong> en pequeñas ventanas de dos dimensiones. Mientras que las capas densas aprenden patrones globales en su espacio global de entrada.</p>
<p>Una característica muy interesante de las capas convolucionales es que una vez aprendida una característica o rasgo visual en un punto de la imagen, la puede <strong>reconocer en cualquier parte de la imagen</strong>. Sin embargo, una red de capas densas tiene que aprender de nuevo el patrón si aparece en otro lugar de la imagen.</p>
<p>Otra característica destacable, es que las capas convolucionales pueden aprender <strong>jerarquías espaciales de patrones</strong>. Una capa aprende patrones básicos, la siguiente patrones compuestos de elementos básicos aprendidos en la capa anterior.</p>
<p>Las capas convolucionales operan sobre matrices de tres ejes, mapas de características. Dos ejes indican las dimensiones: altura y anchura, el tercer eje es el <em>canal</em> en imágenes RGB la dimensión es 3, correspondiendo con cada canal de color. Sin embargo en imágenes en blanco y negro la dimensión es 1 (nivel de gris).</p>
<p>No se conectan todas las entradas (pixels) de la imagen con todas las neuronas, tan solo se hace por pequeñas zonas localizadas (ventanas).</p>
<p><img alt="pequeñas zonas localizadas" src="http://torres.ai/wp-content/uploads/2018/06/Picture.4.2.png" /></p>
<p>Esta ventana va deslizándose por toda la imagen, conectando cada una de ellas con una neurona de la siguiente capa.</p>
<p><img alt="recorrido de la venta por la imagen" src="http://torres.ai/wp-content/uploads/2018/06/Picture.4.3.png" /></p>
<p>La capa convolucional, realiza una reducción de la dimensión de la imagen de entrada, de manera que mediante una ventana de tamaño específico va recorriendo todos los pixel de la imagen de entrada. El movimiento de esta ventana se establece con el parámetro <strong>stride</strong>. Puede ser de un pixel o más.</p>
<p><img alt="&quot;El stride&quot;" src="https://d2l.ai/_images/conv-stride.svg" /></p>
<p>Al tamaño de esta ventana se denomina <strong>kernel</strong>, y corresponde a una matriz cuadrada que abarca tantos pixel como los indicados en este parámetro. Sin embargo, la combinación de estos dos parámetros para el recorrido exploratorio de toda la imagen, deja entrever que unos pixeles participan más que otros, concretamente los pixel más próximos a los bordes, quedan excluidos de más convoluciones.</p>
<p>Para mejorar el barrido de pixel de la imagen, se utiliza el parámetro <strong>padding</strong> que permite añadir a la imagen un bórde extra de pixeles, permitiendo que el <em>kernel</em> (ventana o filtro) y su desplazamiento <em>sride</em> recorra todos los pixeles significativos en más ocasiones.</p>
<p>Una particularidad importante en redes convolucionales, es que se usa el mismo <em>kernel</em> (filtro o ventana) en todas las neuronas de una misma capa, es decir el mismo peso <strong>w</strong> y el mismo sesgo <strong>b</strong>. Esto reduce de forma drástica los parámetros que debe ajustar la red neuronal.</p>
<div class="admonition info">
<p class="admonition-title">varios filtros</p>
<p>Un filtro solo puede detectar una característica de la imagen. Para realizar reconocimientos es necesario detectar más características usando varios filtros al mismo tiempo.</p>
</div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># We define a helper function to calculate convolutions. It initializes</span>
<span class="c1"># the convolutional layer weights and performs corresponding dimensionality</span>
<span class="c1"># elevations and reductions on the input and output</span>
<span class="k">def</span> <span class="nf">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="c1"># (1, 1) indicates that batch size and the number of channels are both 1</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="p">))</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="c1"># Strip the first two dimensions: examples and channels</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="mi">3</span><span class="p">])</span>
<span class="c1"># 1 row and column is padded on either side, so a total of 2 rows or columns are added</span>
<span class="n">conv2d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
<span class="hll"><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
</span><span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<p>Cuando la altura y anchura del kernel no son iguales, también es posible establecer una dimensión adecuada para el parámetro padding.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># We use a convolution kernel with height 5 and width 3. The padding on</span>
<span class="c1"># either side of the height and width are 2 and 1, respectively</span>
<span class="hll"><span class="n">conv2d</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Conv2D</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
</span><span class="n">comp_conv2d</span><span class="p">(</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</code></pre></div>
<div class="admonition note">
<p class="admonition-title">Memoria vs parámetros</p>
<p>Las capas convolucionales necesitan más memoría, ya que almacenan más información de procesamiento. Mientras que las capas densas precisan muchos parámetros para el modelo, que deben ser aprendidos.</p>
</div>
<h2 id="pooling">Pooling</h2>
<p>Las redes convolucionales acompañan a las capas convolucionales de capas de <strong>pooling</strong>, que suelen ser aplicadas inmediantemente después de las capas convolucionales. Las capas <strong>pooling</strong> hacen una simplificación de la información recogida por la capa convolucional y crean una versión condensada de la información contenida.</p>
<p>Aplicar este tipo de capa supone realizar una reducción dimensional de la imagen previa. Hay posibilidad de utilizar el máximo valor, o el valor promedio, de la ventana indicada como kernel</p>
<div class="admonition note">
<p class="admonition-title">El pooling</p>
<p>Una ventana (<em>kernel</em>) de 2 x 2 pixeles, se simplifica a un único pixel.</p>
</div>
<p><img alt="poling 2x2 a 1" src="http://torres.ai/wp-content/uploads/2018/06/Picture4.5.png" /></p>
<p>Hay varias formas de condensar la información. Una opción es utilizar el <em>max_pooling</em>, que se queda con el valor máximo de los que había en la ventana (<em>kernel</em>).</p>
<p>También se puede utilizar <em>average_pooling</em>, donde cada conjunto de valores de pixel se transforma en el valor promedio.</p>
<p><img alt="ejemplo max_pooling" src="http://torres.ai/wp-content/uploads/2018/06/Picture.4.6.png" /></p>
<p>Como la capa pooling se aplica a cada filtro (<em>kernel</em>), y la capa convolucional alberga más de un filtro, se obtendrá una <strong>capa pooling</strong> con tantos filtros de pooling como convolucionales.</p>
<h2 id="red-convolucional-basica">Red convolucional básica</h2>
<p>El dataset de prendas de ropa de Zalando sirve para probar los resultados que se pueden conseguir con un modelo de red neuronal de capas densas, frente a una red con capas convolucionales.</p>
<p><img alt="Ejemplo para comparar" src="https://colab.research.google.com/drive/1VdwtqDSlz1TzNVyWU0R-X9qvrkQ-z7c5?usp=sharing" /></p>
<h1 id="aumento-de-datos">Aumento de datos</h1>
<p>Permite disponer de más datos aplicando variaciones a las imágenes disponibles (rotación, iluminación, contraste,...).</p>
<p>En algunos casos (problemas de segmentación) puede ser necesario aplicar los mismos filtros a otros elementos del dataset relacionados con cada elemento del dataset. Por ejemplo, la máscara en los problemas de segmentación.</p>
<h1 id="segmentacion">Segmentación</h1>
<p>Los problemas de segmentación en imágenes se basan en identificar elementos en la imagen. La estructura de los modelos es diferente a los que solucionan problemas de clasificación.</p>
<h2 id="segmentacion-semantica">Segmentación semántica</h2>
<p>Consiste en determinar los elementos que componen una imagen, detectando su relevancia en la imagen. Etiquetando cada área con una categoría de las clases utilizadas. *Se clasifican los pixels, no los objetos.</p>
<p>En la siguiente imagen se observa como sobre el total de las imagenes se establecen las zonas relevantes a: pasto, avión, edificio, vaca, cielo, camino...</p>
<p><img alt="ejemplo segmentación semantica" src="https://www.researchgate.net/profile/Cristobal-Silva-5/publication/319766387/figure/fig4/AS:538875850625025@1505489422809/Figura-24-Ejemplo-de-Segmentacion-Semantica-31.png" /></p>
<h3 id="segmentacion-binaria">Segmentación binaria</h3>
<p>Es un caso particular de segmentación semática, en el cual solo se clasifica cada pixel: <em>si pertenece al </em><em>fondo</em><em>, o a la </em><em>región de interés</em>**.</p>
<h2 id="segmentacion-de-instancias">Segmentación de instancias</h2>
<p>Consiste en determinar los objetos de la imagnes. <em>Se clasifican los </em><em>pixels</em><em> y los </em><em>objetos</em>**.</p>
<p><img alt="Ejemplo instancias" src="https://cocodataset.org/images/detection-splash.png" /></p>
<h2 id="recursos">Recursos</h2>
<p>La base de datos <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10</a> consiste en un dataset de imágenes cotidianas pertenecientes a 10 clases diferentes. </p>
<p>Dispone de unas 60.000 imágenes a color de 32 x 32. Distribuidas para entrenamiento y validación.</p>
<p>Las clases que dispone son:
- avión
- automóbil
- pájaro
- gato 
- ciervo
- perro
- rana
- caballo
- barco
- camión</p>
<p>Una desventaja de este dataset es el tamaño (32 x 32), ya que son imágenes con baja resolución.</p>
<p>La base de datos <a href="https://cocodataset.org/#home">COCO</a> consiste en un dataset de imágenes etiquetadas con 80 categorías. Se utiliza para entrenar modelos para solucionar problemas de <strong>segmentación de instancias</strong>.</p>
<h1 id="hiperparametros">Hiperparámetros</h1>
<h2 id="tamano-y-numero-de-filtros">Tamaño y número de filtros</h2>
<p>El tamaño de la ventana suele ser 3x3 ó 5x5.
El número de filtros 32 ó 64.</p>
<h1 id="uso-de-redes-ya-disenadas">Uso de redes ya diseñadas</h1>
<p>Incluidas en el framework Keras.</p>
<p><a href="https://keras.io/api/applications/">Keras modelos listos para utilizar</a></p>
<p>Están incluidos en la propia librería y resulta fácil disponer de ellos.</p>
<p>Por ejemplo VGG16</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">keras.applications</span> <span class="kn">import</span> <span class="n">VGG16</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">VGG16</span><span class="p">(</span><span class="n">weights</span><span class="o">=</span><span class="s1">&#39;imagenet&#39;</span><span class="p">)</span>
</code></pre></div>


  




                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            

  
    
  




  


<h4>Cookie consent</h4>
<p>Esta página de apuntes utiliza cookies para reconocer las visitas, medir la efectividad de la documentación y averiguar si encuentras aquello que buscas o cómo has llegado a estos apuntes. Con tu consentimiento, me ayudas a mejorar estos materiales.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
      
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="analytics" checked>
          <span class="task-list-indicator"></span>
          Google Analytics
        <label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.expand"], "search": "../../assets/javascripts/workers/search.3de43c86.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.ce0331ff.min.js"></script>
      
    
    
  </body>
</html>